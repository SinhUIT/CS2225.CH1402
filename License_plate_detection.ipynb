{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "License_plate_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-mPXaWIZZjJh"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lpb3QxmXIJK"
      },
      "source": [
        "# **<center>LICENSE PLATE RECOGNITION</center>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FutM7_2CSMWt"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0gW9abSn8la"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/StudyingAtUIT/Master/CS2225.CH1402-dev')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRikr7y-YELG"
      },
      "source": [
        "## **1. Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adDZ6jMISI9O"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from local_utils import detect_lp\n",
        "from os.path import splitext,basename\n",
        "from keras.models import model_from_json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf24rZQsYOZl"
      },
      "source": [
        "## **2. Plate Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ov8CQVbSI9b"
      },
      "source": [
        "def load_model(path):\n",
        "    try:\n",
        "        path = splitext(path)[0]\n",
        "        with open('%s.json' % path, 'r') as json_file:\n",
        "            model_json = json_file.read()\n",
        "        model = model_from_json(model_json, custom_objects={})\n",
        "        model.load_weights('%s.h5' % path)\n",
        "        print(\"Loading model successfully...\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0BNBcjGSI9b"
      },
      "source": [
        "wpod_net_path = \"/content/drive/MyDrive/StudyingAtUIT/Master/CS2225.CH1402-dev/nhan_dien_bien_so/resources/wpod-net.json\"\n",
        "wpod_net = load_model(wpod_net_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIu65jXpSI9b"
      },
      "source": [
        "def preprocess_image(image_path,resize=False):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img / 255\n",
        "    if resize:\n",
        "        img = cv2.resize(img, (224,224))\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "XRTNuzY_SI9c"
      },
      "source": [
        "image_paths = glob.glob(\"/content/drive/MyDrive/StudyingAtUIT/Master/CS2225.CH1402-dev/nhan_dien_bien_so/resources/Plate_examples2/*.jpg\")\n",
        "print(\"Found %i images...\"%(len(image_paths)))\n",
        "\n",
        "# Visualize data in subplot \n",
        "fig = plt.figure(figsize=(12,8))\n",
        "cols = 5\n",
        "rows = 4\n",
        "fig_list = []\n",
        "for i in range(cols*rows):\n",
        "    fig_list.append(fig.add_subplot(rows,cols,i+1))\n",
        "    title = splitext(basename(image_paths[i]))[0]\n",
        "    fig_list[-1].set_title(title)\n",
        "    img = preprocess_image(image_paths[i],True)\n",
        "    plt.axis(False)\n",
        "    plt.imshow(img)\n",
        "\n",
        "plt.tight_layout(True)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5V3gJpQxSI9c"
      },
      "source": [
        "def get_plate(image_path, Dmax=608, Dmin=256):\n",
        "    vehicle = preprocess_image(image_path)\n",
        "    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n",
        "    for j in range(0,50):\n",
        "      try:\n",
        "        Dmin=Dmin+j\n",
        "        side = int(ratio * Dmin)\n",
        "        bound_dim = min(side, Dmax)\n",
        "        _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n",
        "        break\n",
        "      except AssertionError: \n",
        "        pass\n",
        "    return LpImg, cor\n",
        "\n",
        "test_image = image_paths[2]\n",
        "# test_image='/content/drive/MyDrive/StudyingAtUIT/Master/CS2225.CH1402-dev/nhan_dien_bien_so/resources/Plate_examples2/1_49_1346295639_71_1_Lexus-LX570_2.jpg'\n",
        "LpImg,cor = get_plate(test_image)\n",
        "print(\"Detect %i plate(s) in\"%len(LpImg),splitext(basename(test_image))[0])\n",
        "print(\"Coordinate of plate(s) in image: \\n\", cor)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(False)\n",
        "plt.imshow(preprocess_image(test_image))\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(False)\n",
        "plt.imshow(LpImg[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPSzn_V_SI9c"
      },
      "source": [
        "def draw_box(image_path, cor, thickness=3): \n",
        "    pts=[]  \n",
        "    x_coordinates=cor[0][0]\n",
        "    y_coordinates=cor[0][1]\n",
        "    for i in range(4):\n",
        "        pts.append([int(x_coordinates[i]),int(y_coordinates[i])])\n",
        "    \n",
        "    pts = np.array(pts, np.int32)\n",
        "    pts = pts.reshape((-1,1,2))\n",
        "    vehicle_image = preprocess_image(image_path)\n",
        "    \n",
        "    cv2.polylines(vehicle_image,[pts],True,(0,255,0),thickness)\n",
        "    return vehicle_image\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(False)\n",
        "plt.imshow(draw_box(test_image,cor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXk6M64LYi-L"
      },
      "source": [
        "## **3. Character Segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq-ORDwWe_2I"
      },
      "source": [
        "if (len(LpImg)):\r\n",
        "    plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\r\n",
        "    \r\n",
        "    gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\r\n",
        "    blur = cv2.GaussianBlur(gray,(7,7),0)\r\n",
        "    \r\n",
        "    binary = cv2.threshold(blur, 180, 255,\r\n",
        "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\r\n",
        "    kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\r\n",
        "    thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Awq-TnhOsE"
      },
      "source": [
        "def sort_contours(cnts,reverse = False):\r\n",
        "    i = 0\r\n",
        "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\r\n",
        "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\r\n",
        "                                        key=lambda b: b[1][i], reverse=reverse))\r\n",
        "    return cnts\r\n",
        "\r\n",
        "cont, _  = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n",
        "\r\n",
        "test_roi = plate_image.copy()\r\n",
        "\r\n",
        "crop_characters = []\r\n",
        "\r\n",
        "digit_w, digit_h = 30, 60\r\n",
        "\r\n",
        "for c in sort_contours(cont):\r\n",
        "    (x, y, w, h) = cv2.boundingRect(c)\r\n",
        "    # print(h,w)\r\n",
        "    ratio = h/w\r\n",
        "    # print(ratio)\r\n",
        "    if 1<=ratio<=3.5: # Only select contour with defined ratio\r\n",
        "        if h/plate_image.shape[0]>=0.5: # Select contour which has the height larger than 50% of the plate\r\n",
        "            cv2.rectangle(test_roi, (x, y), (x + w, y + h), (0, 255,0), 2)\r\n",
        "\r\n",
        "            curr_num = thre_mor[y:y+h,x:x+w]\r\n",
        "            curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\r\n",
        "            _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\r\n",
        "            crop_characters.append(curr_num)\r\n",
        "            \r\n",
        "print(\"Detect {} letters...\".format(len(crop_characters)))   \r\n",
        "fig = plt.figure(figsize=(10,6))\r\n",
        "plt.axis(False)\r\n",
        "plt.imshow(test_roi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztBF03YAhfR7"
      },
      "source": [
        "\r\n",
        "fig = plt.figure(figsize=(14,4))\r\n",
        "grid = gridspec.GridSpec(ncols=len(crop_characters),nrows=1,figure=fig)\r\n",
        "\r\n",
        "for i in range(len(crop_characters)):\r\n",
        "    fig.add_subplot(grid[i])\r\n",
        "    plt.axis(False)\r\n",
        "    plt.imshow(crop_characters[i],cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_HnwljaWQXT"
      },
      "source": [
        "##**4. Character Recognition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mPXaWIZZjJh"
      },
      "source": [
        "### **4.1. Visualize dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bM29t9xWLDU"
      },
      "source": [
        "dataset_paths = glob.glob(\"/content/drive/MyDrive/StudyingAtUIT/Master/CS2225.CH1402-dev/dataset_characters/**/*.jpg\")\r\n",
        "\r\n",
        "cols=4\r\n",
        "rows=3\r\n",
        "fig = plt.figure(figsize=(10,8))\r\n",
        "plt.rcParams.update({\"font.size\":14})\r\n",
        "grid = gridspec.GridSpec(ncols=cols,nrows=rows,figure=fig)\r\n",
        "\r\n",
        "np.random.seed(45)\r\n",
        "rand = np.random.randint(0,len(dataset_paths),size=(cols*rows))\r\n",
        "\r\n",
        "for i in range(cols*rows):\r\n",
        "    fig.add_subplot(grid[i])\r\n",
        "    image = load_img(dataset_paths[rand[i]])\r\n",
        "    label = dataset_paths[rand[i]].split(os.path.sep)[-2]\r\n",
        "    plt.title('\"{:s}\"'.format(label))\r\n",
        "    plt.axis(False)\r\n",
        "    plt.imshow(image)\r\n",
        "\r\n",
        "plt.savefig(\"Visualize_dataset.jpg\",dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziGFo7PRys7i"
      },
      "source": [
        "### **4.2. Pre-process Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7p22zjVyP5N"
      },
      "source": [
        "X=[]\r\n",
        "labels=[]\r\n",
        "\r\n",
        "for image_path in dataset_paths:\r\n",
        "  label = image_path.split(os.path.sep)[-2]\r\n",
        "  image=load_img(image_path,target_size=(80,80))\r\n",
        "  image=img_to_array(image)\r\n",
        "\r\n",
        "  X.append(image)\r\n",
        "  labels.append(label)\r\n",
        "\r\n",
        "X = np.array(X,dtype=\"float16\")\r\n",
        "labels = np.array(labels)\r\n",
        "\r\n",
        "print(\"[INFO] Find {:d} images with {:d} classes\".format(len(X),len(set(labels))))\r\n",
        "\r\n",
        "\r\n",
        "lb = LabelEncoder()\r\n",
        "lb.fit(labels)\r\n",
        "labels = lb.transform(labels)\r\n",
        "y = to_categorical(labels)\r\n",
        "\r\n",
        "np.save('license_character_classes.npy', lb.classes_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grGb4Z2XfrBH"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZCyHcMnggjl"
      },
      "source": [
        "image_gen = ImageDataGenerator(rotation_range=10,\r\n",
        "                              width_shift_range=0.1,\r\n",
        "                              height_shift_range=0.1,\r\n",
        "                              shear_range=0.1,\r\n",
        "                              zoom_range=0.1,\r\n",
        "                              fill_mode=\"nearest\"\r\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nD9qMu4zgYQ"
      },
      "source": [
        "def create_model(lr=1e-4,decay=1e-4/25, training=False,output_shape=y.shape[1]):\r\n",
        "    baseModel = MobileNetV2(weights=\"imagenet\", \r\n",
        "                            include_top=False,\r\n",
        "                            input_tensor=Input(shape=(80, 80, 3)))\r\n",
        "\r\n",
        "    headModel = baseModel.output\r\n",
        "    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\r\n",
        "    headModel = Flatten(name=\"flatten\")(headModel)\r\n",
        "    headModel = Dense(128, activation=\"relu\")(headModel)\r\n",
        "    headModel = Dropout(0.5)(headModel)\r\n",
        "    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\r\n",
        "    \r\n",
        "    model = Model(inputs=baseModel.input, outputs=headModel)\r\n",
        "    \r\n",
        "    if training:\r\n",
        "        for layer in baseModel.layers:\r\n",
        "            layer.trainable = True\r\n",
        "        optimizer = Adam(lr=lr, decay = decay)\r\n",
        "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])    \r\n",
        "        \r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8VfoT0l0hxF"
      },
      "source": [
        "INIT_LR = 1e-4\r\n",
        "EPOCHS = 30\r\n",
        "\r\n",
        "model = create_model(lr=INIT_LR, decay=INIT_LR/EPOCHS,training=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT8PqzJQXEGE"
      },
      "source": [
        "### **4.3 Train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RA4ItuS1B4l"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "my_checkpointer = [\r\n",
        "                EarlyStopping(monitor='val_loss', patience=5, verbose=0),\r\n",
        "                ModelCheckpoint(filepath=\"License_character_recognition.h5\", verbose=1, save_weights_only=True)\r\n",
        "                ]\r\n",
        "\r\n",
        "result = model.fit(image_gen.flow(trainX, trainY, batch_size=BATCH_SIZE), \r\n",
        "                   steps_per_epoch=len(trainX) // BATCH_SIZE, \r\n",
        "                   validation_data=(testX, testY), \r\n",
        "                   validation_steps=len(testX) // BATCH_SIZE, \r\n",
        "                   epochs=EPOCHS, callbacks=my_checkpointer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riFompgR1Z7q"
      },
      "source": [
        "### **4.4 Trainning result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSRojaYE1kSR"
      },
      "source": [
        "fig = plt.figure(figsize=(14,5))\r\n",
        "grid=gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\r\n",
        "fig.add_subplot(grid[0])\r\n",
        "plt.plot(result.history['accuracy'], label='training accuracy')\r\n",
        "plt.plot(result.history['val_accuracy'], label='val accuracy')\r\n",
        "plt.title('Accuracy')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "fig.add_subplot(grid[1])\r\n",
        "plt.plot(result.history['loss'], label='training loss')\r\n",
        "plt.plot(result.history['val_loss'], label='val loss')\r\n",
        "plt.title('Loss')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.legend()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzrcqW_WZtRO"
      },
      "source": [
        "### **4.2. Usage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ydGeGmLj9_K"
      },
      "source": [
        "json_file = open('/content/drive/MyDrive/StudyingAtUIT/Master/CS2225.CH1402-dev/nhan_dien_bien_so/resources/MobileNets_character_recognition.json', 'r')\r\n",
        "loaded_model_json = json_file.read()\r\n",
        "json_file.close()\r\n",
        "model = model_from_json(loaded_model_json)\r\n",
        "model.load_weights(\"/content/drive/MyDrive/StudyingAtUIT/Master/CS2225.CH1402-dev/nhan_dien_bien_so/resources/License_character_recognition_weight.h5\")\r\n",
        "print(\"[INFO] Model loaded successfully...\")\r\n",
        "\r\n",
        "labels = LabelEncoder()\r\n",
        "labels.classes_ = np.load('/content/drive/MyDrive/StudyingAtUIT/Master/CS2225.CH1402-dev/nhan_dien_bien_so/resources/license_character_classes.npy')\r\n",
        "print(\"[INFO] Labels loaded successfully...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr8VuTb9qXP9"
      },
      "source": [
        "def predict_from_model(image,model,labels):\r\n",
        "    image = cv2.resize(image,(80,80))\r\n",
        "    image = np.stack((image,)*3, axis=-1)\r\n",
        "    prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis,:]))])\r\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwZAS0Ccqbrg"
      },
      "source": [
        "fig = plt.figure(figsize=(15,3))\r\n",
        "cols = len(crop_characters)\r\n",
        "grid = gridspec.GridSpec(ncols=cols,nrows=1,figure=fig)\r\n",
        "\r\n",
        "final_string = ''\r\n",
        "for i,character in enumerate(crop_characters):\r\n",
        "    fig.add_subplot(grid[i])\r\n",
        "    title = np.array2string(predict_from_model(character,model,labels))\r\n",
        "    plt.title('{}'.format(title.strip(\"'[]\"),fontsize=20))\r\n",
        "    final_string+=title.strip(\"'[]\")\r\n",
        "    plt.axis(False)\r\n",
        "    plt.imshow(character,cmap='gray')\r\n",
        "\r\n",
        "print(final_string)\r\n",
        "#plt.savefig('final_result.png', dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dq5KsoZFSI9d"
      },
      "source": [
        "# Viualize all obtained plate images \n",
        "fig = plt.figure(figsize=(12,6))\n",
        "cols = 5\n",
        "rows = 4\n",
        "fig_list = []\n",
        "dmin=256\n",
        "for i in range(cols*rows):\n",
        "    fig_list.append(fig.add_subplot(rows,cols,i+1))\n",
        "    title = splitext(basename(image_paths[i]))[0]\n",
        "    fig_list[-1].set_title(title)\n",
        "    for j in range(0,50):\n",
        "      try:\n",
        "        dmin+=j\n",
        "        LpImg,_ = get_plate(image_paths[i],Dmin=dmin)\n",
        "        break\n",
        "      except AssertionError: \n",
        "        pass\n",
        "\n",
        "    plt.axis(False)\n",
        "    plt.imshow(LpImg[0])\n",
        "\n",
        "plt.tight_layout(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgYeqLRcb7pn"
      },
      "source": [
        "if (len(LpImg)): #check if there is at least one license image\r\n",
        "    # Scales, calculates absolute values, and converts the result to 8-bit.\r\n",
        "    plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\r\n",
        "    \r\n",
        "    # convert to grayscale and blur the image\r\n",
        "    gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\r\n",
        "    blur = cv2.GaussianBlur(gray,(7,7),0)\r\n",
        "    \r\n",
        "    # Applied inversed thresh_binary \r\n",
        "    binary = cv2.threshold(blur, 180, 255,\r\n",
        "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\r\n",
        "    ## Applied dilation \r\n",
        "    kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\r\n",
        "    thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXNfqhriSI9e"
      },
      "source": [
        "# **The End!**"
      ]
    }
  ]
}