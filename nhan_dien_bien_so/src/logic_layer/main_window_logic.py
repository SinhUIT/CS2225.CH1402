# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'untitled.ui'
#
# Created by: PyQt5 UI code generator 5.15.1
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

import cv2
from PyQt5 import QtGui, QtWidgets
from PyQt5.QtGui import QPixmap
from src.presentation_layer.main_window import Ui_MainWindow
from src.license_plate_recognition.license_plate_recognition import get_plate, load_model
import numpy as np
import matplotlib.pyplot as plt
from keras.models import model_from_json
from sklearn.preprocessing import LabelEncoder


class MainWindowLogic(Ui_MainWindow):
    def __init__(self, MainWindow):
        super().__init__()
        self.setupUi(MainWindow)
        self.model = load_model('resources/wpod-net')
        json_file = open('resources/MobileNets_character_recognition.json', 'r')
        loaded_model_json = json_file.read()
        json_file.close()
        self.model1 = model_from_json(loaded_model_json)
        self.model1.load_weights("resources/License_character_recognition_weight.h5")

        self.labels = LabelEncoder()
        self.labels.classes_ = np.load('resources/license_character_classes.npy')

    def process(self):
        self.actionImport.triggered.connect(self.image_load)

    def image_load(self):
        fname = QtWidgets.QFileDialog.getOpenFileName(self, 'Open file', 'c:\\', "Image files (*.jpg *.gif)")
        imagePath = fname[0]
        pixmap = QPixmap(imagePath)
        self.lb_input.setScaledContents(True)
        self.lb_input.setPixmap(QPixmap(pixmap))
        # self.resize(pixmap.width(), pixmap.height())
        self.extract_license_plate(fname[0])

    def extract_license_plate(self, file_name):
        vehicle, LpImg, cor = get_plate(self.model, file_name)
        # lpimg = np.array(LpImg[0]).reshape(2048, 2048).astype(np.int32)
        # bytesPerLine = 3 * LpImg[0].shape[0]

        data = LpImg[0].astype(np.float32)
        plt.imsave('tmp/lptmp.png', data)
        pixmap = QPixmap('tmp/lptmp.png')
        self.lb_plate.setScaledContents(True)
        self.lb_plate.setPixmap(QPixmap(pixmap))
        # self.resize(qimage.width(), qimage.height())
        self.recognition(LpImg[0])

    def sort_contours(self, cnts, reverse=False):
        i = 0
        boundingBoxes = [cv2.boundingRect(c) for c in cnts]
        (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),
                                            key=lambda b: b[1][i], reverse=reverse))
        return cnts

    def predict_from_model(self, image, model, labels):
        image = cv2.resize(image, (80, 80))
        image = np.stack((image,) * 3, axis=-1)
        prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis, :]))])
        return prediction

    def recognition(self, lpimg):
        if (len(lpimg)):  # check if there is at least one license image
            # Scales, calculates absolute values, and converts the result to 8-bit.
            plate_image = cv2.convertScaleAbs(lpimg, alpha=(255.0))

            # convert to grayscale and blur the image
            gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)
            blur = cv2.GaussianBlur(gray, (7, 7), 0)

            # Applied inversed thresh_binary
            binary = cv2.threshold(blur, 180, 255,
                                   cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

            kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)

            cont, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            # creat a copy version "test_roi" of plat_image to draw bounding box
            test_roi = plate_image.copy()

            # Initialize a list which will be used to append charater image
            crop_characters = []

            # define standard width and height of character
            digit_w, digit_h = 30, 60

            for c in self.sort_contours(cont):
                (x, y, w, h) = cv2.boundingRect(c)
                ratio = h / w
                if 1 <= ratio <= 3.5:  # Only select contour with defined ratio
                    if h / plate_image.shape[0] >= 0.5:  # Select contour which has the height larger than 50% of the plate
                        # Draw bounding box arroung digit number
                        cv2.rectangle(test_roi, (x, y), (x + w, y + h), (0, 255, 0), 2)

                        # Sperate number and gibe prediction
                        curr_num = thre_mor[y:y + h, x:x + w]
                        curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))
                        _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                        crop_characters.append(curr_num)

            final_string = ''
            for i, character in enumerate(crop_characters):
                title = np.array2string(self.predict_from_model(character, self.model1, self.labels))
                final_string += title.strip("'[]")
            self.lb_result.setText(final_string)